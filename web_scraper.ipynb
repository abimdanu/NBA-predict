{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"data\"\n",
    "STANDINGS_DIRECTORY = os.path.join(DATA_DIRECTORY, \"standings\")\n",
    "SCORES_DIRECTORY = os.path.join(DATA_DIRECTORY, \"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(2018, 2023))\n",
    "months = [\"october\",\n",
    "          \"november\",\n",
    "          \"december\",\n",
    "          \"january\",\n",
    "          \"february\",\n",
    "          \"march\",\n",
    "          \"april\",\n",
    "          \"may\",\n",
    "          \"june\"]\n",
    "\n",
    "url_start = \"https://www.basketball-reference.com/leagues/NBA_{year}_games-{month}.html\"\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        url = url_start.format(year=year, month=month)\n",
    "        html_data = requests.get(url)\n",
    "\n",
    "        with open(\"data/standings/{year}_{month}_games.html\".format(year=year, month=month), \"w+\", encoding=\"utf-8\") as f:\n",
    "            f.write(html_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxscore_html_month(sleepTime=4, fileIndex=-1, files=os.listdir(STANDINGS_DIRECTORY)):\n",
    "    # Membuka data HTML bulan & tahun tertentu dari folder 'standings'\n",
    "    with open(\"data/standings/{filename}\".format(filename=files[fileIndex]), \"r\", encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all(\"a\")\n",
    "    hrefs = [link.get(\"href\") for link in links]\n",
    "    box_scores = [f\"https://www.basketball-reference.com{link}\" for link in hrefs if link and \"boxscore\" in link and \".html\" in link]\n",
    "\n",
    "    # Men-downlaod tabel box score\n",
    "    for index in range(len(box_scores)):\n",
    "        boxscore_url = box_scores[index]\n",
    "        save_path = os.path.join(SCORES_DIRECTORY, boxscore_url.split(\"/\")[-1])\n",
    "\n",
    "        html = requests.get(boxscore_url)\n",
    "\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        with open(save_path, \"w+\", encoding=\"utf-8\") as f:\n",
    "            f.write(str(html.text))\n",
    "        time.sleep(sleepTime)\n",
    "    \n",
    "    print(f\"File '{files[fileIndex]}' selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_boxscore_html_month_test(sleepTime=4, fileIndex=-1, files=os.listdir(STANDINGS_DIRECTORY)):\n",
    "#     # Membuka data HTML bulan & tahun tertentu dari folder 'standings'\n",
    "#     with open(\"data/standings/{filename}\".format(filename=files[fileIndex]), \"r\", encoding=\"utf-8\") as f:\n",
    "#         html = f.read()\n",
    "\n",
    "#     soup = BeautifulSoup(html)\n",
    "#     links = soup.find_all(\"a\")\n",
    "#     hrefs = [link.get(\"href\") for link in links]\n",
    "#     box_scores = [f\"https://www.basketball-reference.com{link}\" for link in hrefs if link and \"boxscore\" in link and \".html\" in link]\n",
    "\n",
    "#     # Men-downlaod tabel box score\n",
    "#     for index in range(len(box_scores)):\n",
    "#         boxscore_url = box_scores[index]\n",
    "#         save_path = os.path.join(SCORES_DIRECTORY, boxscore_url.split(\"/\")[-1])\n",
    "\n",
    "#         html = requests.get(boxscore_url)\n",
    "\n",
    "#         soup = BeautifulSoup(html.text, 'html.parser')\n",
    "#         # with open(save_path, \"w+\", encoding=\"utf-8\") as f:\n",
    "#         #     f.write(str(html.text))\n",
    "#         content_element = soup.find(\"div\", id=\"content\")\n",
    "\n",
    "#         if content_element:\n",
    "#             with open(os.path.join(os.path.join(DATA_DIRECTORY, \"scores_cancel\"), boxscore_url.split(\"/\")[-1]), \"w+\", encoding=\"utf-8\") as f:\n",
    "#                 f.write(str(content_element))\n",
    "#         else:\n",
    "#             print(f\"Elemen id=\\\"content\\\" tidak ditemukan pada{index}:{boxscore_url}\")\n",
    "\n",
    "#         # jeda agar request rate tidak terlalu besar\n",
    "#         time.sleep(sleepTime)\n",
    "    \n",
    "#     print(f\"File '{files[fileIndex]}' selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startIndex = 1 # 36 file sudah selesai, lanjut ke 37 (37 tdk ada --> sudah selesai)\n",
    "files = os.listdir(STANDINGS_DIRECTORY)[startIndex:]\n",
    "\n",
    "for i in range(len(os.listdir(STANDINGS_DIRECTORY))-1):\n",
    "    get_boxscore_html_month(sleepTime=3.5, fileIndex=i, files=files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
